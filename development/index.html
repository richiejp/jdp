<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Development · JDP</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>JDP</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../bugrefs/">BugRefs</a></li><li><a class="toctext" href="../conf/">Conf</a></li><li><a class="toctext" href="../functional/">Functional</a></li><li><a class="toctext" href="../repository/">Repository</a></li><li><a class="toctext" href="../trackers/">Trackers</a></li></ul></li><li class="current"><a class="toctext" href>Development</a><ul class="internal"><li><a class="toctext" href="#Universal-Principals-1">Universal Principals</a></li><li><a class="toctext" href="#Life-cycle-1">Life cycle</a></li><li><a class="toctext" href="#Library-coding-standards-1">Library coding standards</a></li><li class="toplevel"><a class="toctext" href="#Project-status-1">Project status</a></li><li class="toplevel"><a class="toctext" href="#Architecture-1">Architecture</a></li><li><a class="toctext" href="#Outer-1">Outer</a></li><li><a class="toctext" href="#Inner-1">Inner</a></li><li class="toplevel"><a class="toctext" href="#Motivation-1">Motivation</a></li><li><a class="toctext" href="#Concrete-1">Concrete</a></li><li><a class="toctext" href="#Less-Concrete-1">Less Concrete</a></li><li><a class="toctext" href="#Existing-solutions-1">Existing solutions</a></li><li class="toplevel"><a class="toctext" href="#Design-Decisions-1">Design Decisions</a></li><li><a class="toctext" href="#Not-a-source-of-truth-1">Not a source of truth</a></li><li><a class="toctext" href="#Distributed-Data-Cache-1">Distributed Data Cache</a></li><li><a class="toctext" href="#Mostly-in-memory-data-1">Mostly in memory data</a></li><li><a class="toctext" href="#Julia-1">Julia</a></li><li><a class="toctext" href="#Jupyter-(formally-known-as-IPython)-Notebooks-for-reports/scripts-1">Jupyter (formally known as IPython) Notebooks for reports/scripts</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Development</a></li></ul><a class="edit-page" href="https://github.com/richiejp/jdp/blob/master/docs/src/development.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Development</span><a class="fa fa-bars" href="#"></a></div></header><p>Here we discuss the development of JDP itself for anyone who wishes to contribute or understand what kind of madness this was born from.</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>You should at the very least read the coding standards and principals before contributing to the core library.</p></div></div><h1><a class="nav-anchor" id="Coding-standards-and-principals-1" href="#Coding-standards-and-principals-1">Coding standards and principals</a></h1><p>The standards and principals change depending on the stage of the product/component life cycle and what the component is. For now there are three stages to the life cycle. These are listed below along with the principals you should follow.</p><p>Components don&#39;t necessarily need to start as experimental and progress in a linear fashion. They can be added at any stage. Use the stage specific principals to decide what stage to use.</p><p>Components are also differentiated by type: library, script and report. The life cycle stages only apply to the library and to the scripts which automate core functionality (e.g. caching data in the master node).</p><p>The reason for having such a complex system of principles is to take advantage of the bar-bell strategy. So that we do not have to compromise between moving quickly to test new ideas and moving slowly to be robust.</p><div class="admonition warning"><div class="admonition-title">Warning</div><div class="admonition-text"><p>Principals and maxims are never perfect. They just provide a common point of reference so that our productivity vectors sum to a value greater than anyone&#39;s individual magnitude.</p></div></div><h2><a class="nav-anchor" id="Universal-Principals-1" href="#Universal-Principals-1">Universal Principals</a></h2><p>These apply all the time</p><ul><li>The Silver Rule<ul><li>Do <em>not</em> do to others what you would <em>not</em> like to be done to you.</li></ul></li><li>Be polite, but critical and seek criticism<ul><li>We want the correct solution not to feel like we have the correct solution.</li></ul></li><li>Do the easiest thing to change later<ul><li>When in doubt, take the path which is easiest to leave later.</li></ul></li><li>Show me the code<ul><li>Compare your options, make a hypothesis, prove it. (preference for action).</li></ul></li><li>Small batch sizes<ul><li>Make your feeback loop as tight as possible. Risk making your PRs too small, never too big.</li></ul></li><li>Rule of three<ul><li>Sane DRY</li><li>If you need to do something once; write it inline, twice; copy and paste, three times; create an abstraction.</li></ul></li><li>The solution should be simpler than the problem<ul><li>Avoid unnecessary complexity.</li></ul></li></ul><h2><a class="nav-anchor" id="Life-cycle-1" href="#Life-cycle-1">Life cycle</a></h2><h3><a class="nav-anchor" id="Experimental-1" href="#Experimental-1">Experimental</a></h3><p>The proof of concept (POC) stage which allows you to just make it work in the shortest time possible. You are free to take on technical debt at this stage and take shortcuts.</p><p>Experimental components can be merged, but will be deleted if they are abandoned. They must align with the below principals otherwise they are just poorly written features and won&#39;t be merged.</p><ul><li>Create a falsifiable hypothesis<ul><li>Clearly state what you are trying to prove, what failure would look like and what success would be. A component or PR can only be categorised as experimental if it is clearly an experiment.</li></ul></li><li>Do not over-engineer<ul><li>Just do the simplest, easiest thing to prove the feature&#39;s viability. Use workarounds to solve problems further down the stack. Do not generalise if a specific solution will meet your current requirements regardless of the consequences.</li></ul></li><li>Track your technical debt<ul><li>You need to keep a list of your technical debt (i.e. a TODO list) which can be used to estimate the cost of turning an experimental component into a stable one.</li></ul></li></ul><h3><a class="nav-anchor" id="Stable-1" href="#Stable-1">Stable</a></h3><p>Components and code which we won&#39;t delete without obsoleting them first.</p><ul><li>Think in the long term<ul><li>Assume your code will be run for 10 years and that any mistake will cost many times your own labor and that any improvement will have a huge payoff.</li></ul></li><li>Document once instead of answering many<ul><li>It is better to spend a few hours documenting than many hours answering.</li></ul></li><li>Upstream first<ul><li>Propagate your fixes back to the community and...</li></ul></li><li>Fix whatever needs to be fixed<ul><li>Fixing problems further down the stack can create a long chain-reaction (fractal) of events which eventually benefit us much more than whatever your original task was. Fix root causes, don&#39;t write workarounds.</li></ul></li></ul><h3><a class="nav-anchor" id="Legacy-1" href="#Legacy-1">Legacy</a></h3><p>Components or APIs which can only be accessed through a versioned interface and only use versioned interfaces. That is, the function names and/or namespaces have the version number in the name. The behaviour of versioned interfaces does not change allowing scripts or reports to use them indefinitely without any maintenance due to changes in the library. Legacy components are deleted if they are not used enough.</p><p>Otherwise the principals are the same as the Stable stage.</p><h2><a class="nav-anchor" id="Library-coding-standards-1" href="#Library-coding-standards-1">Library coding standards</a></h2><p>This applies to code providing core functionality of the project. This includes some scripts and reports, but we will just refer to them as the library coding standards.</p><h3><a class="nav-anchor" id="Documentation-and-commenting-1" href="#Documentation-and-commenting-1">Documentation and commenting</a></h3><p>Use documentation strings wherever possible, these are vastly more useful than inline comments. Only use inline comments for annotating very unusual code.</p><h3><a class="nav-anchor" id="Prefer-explicit-over-implicit-1" href="#Prefer-explicit-over-implicit-1">Prefer explicit over implicit</a></h3><p>Type annotate all interfaces. Learn Julia&#39;s type system use it to lock down your code. Type parameters, abstract types and multiple dispatch allow for so much freedom it is rarely desirable to use implicit types (in function arguments or structs).</p><p>Implicit types are often OK for local variables, but adding type annotations can help make code clearer.</p><h1><a class="nav-anchor" id="Project-status-1" href="#Project-status-1">Project status</a></h1><p>See the documentation for each module. At the time of writing, most of the project needs cleaning up.</p><h1><a class="nav-anchor" id="Architecture-1" href="#Architecture-1">Architecture</a></h1><p>The following diagrams are only to help you visualise the project. They are not a design specification or very accurate. For more details see the individual component documentation.</p><h2><a class="nav-anchor" id="Outer-1" href="#Outer-1">Outer</a></h2><p><img src="../outer_arch.svg" alt/></p><h2><a class="nav-anchor" id="Inner-1" href="#Inner-1">Inner</a></h2><p><img src="../inner_arch.svg" alt/></p><h1><a class="nav-anchor" id="Motivation-1" href="#Motivation-1">Motivation</a></h1><h2><a class="nav-anchor" id="Concrete-1" href="#Concrete-1">Concrete</a></h2><p>We want to spend as little time as possible reading test results and logs while maximising the error (or bug) detection rate. We also want to report all relevant information, and only the relevant information, to any interested parties for a given error using the least amount of time.</p><p>The manual process for identifying errors involves looking at information from several sources, identifying relations and reporting those relations to a number of different consumers. There may be several persons forming a tree (in the simple case) or a cyclical directed graph (practically speaking), collecting and processing information then passing it along.</p><p>The information is collected from sources such as OpenQA or a manual test run. Points of interest are identified, these are inputted into an issue tracker (commonly Bugzilla) and then the bugs are aggregated into reports. The bugs are then passed back to OpenQA (or whatever) to mark failing test cases or some other anomaly (bug tagging).</p><p>We have a number of issues with this:</p><ol><li>Many of the data sources are very slow (e.g. OpenQA, Bugzilla)</li><li>Remote sources are often not available due to the network or other system failure</li><li>The same information is encoded in many different ways</li><li>Log files are often very large and noisy</li><li>Different consumers of error data require different levels of detail</li><li>Different consumers of error data require different views of the data</li><li>What is considered a pass or failure by a given test runner (e.g. OpenQA, Slenkins, LTP upstream test runner) may be incorrect.</li><li>Similar to 7. a skipped test may be an error</li><li>There are many data consumers, each accepting different formats or views of the data.</li><li>Etc.</li></ol><h2><a class="nav-anchor" id="Less-Concrete-1" href="#Less-Concrete-1">Less Concrete</a></h2><p>Furthermore we are lacking in tools to automate arbitrary workflows given the various data sources and sinks available to us. Therefor we would like to create an environment which allows for easy experimentation/prototyping where the heavy lifting has already been done and any algorithm can be implemented on the data commonly available to us.</p><h2><a class="nav-anchor" id="Existing-solutions-1" href="#Existing-solutions-1">Existing solutions</a></h2><p>Attempts have been made to solve some of these problems in the OpenQA web UI or with a stand-alone script which queries various sources and produces some output. There are a number of problems with these approaches.</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>This is not an exhaustive list. These are just the solutions which tend to be automatically chosen.</p></div></div><h3><a class="nav-anchor" id="OpenQA-1" href="#OpenQA-1">OpenQA</a></h3><ol><li>It is rigid</li><li>It is slow</li><li>Remote data is not replicated to your local instance</li><li>It is responsible for running the tests (which is a big responsibility)</li></ol><p>Theoretically all of these can be solved except for (4). Practically speaking, solving any of them would be a huge challenge. Not least because the iteration time for developing a new feature is very slow and the process is cumbersome.</p><p>However some improvements in this area can and should be made to OpenQA. I propose that such improvements can be prototyped in JDP where the iteration time is much smaller and mistakes won&#39;t disrupt all testing.</p><h3><a class="nav-anchor" id="Various-scripts-1" href="#Various-scripts-1">Various scripts</a></h3><ol><li>Little sharing of code (no general library for writing such scripts)</li><li>No local data cache</li><li>No data normalisation between sources</li><li>No common data visualisation</li></ol><p>There may be a script somewhere which is evolving to solve some of these issues (maybe for performance testing). I think some of these scripts could be merged with the JDP project so they are not necessarily an alternative solution although doing so may cause some unnecessary friction.</p><h1><a class="nav-anchor" id="Design-Decisions-1" href="#Design-Decisions-1">Design Decisions</a></h1><p>These decisions should follow from the motivation or requirements of the project.</p><h2><a class="nav-anchor" id="Not-a-source-of-truth-1" href="#Not-a-source-of-truth-1">Not a source of truth</a></h2><p>JDP is not a primary data store. It caches data (see next section) from other sources (trackers) and posts data back to other stores. This allows the data cache to be deleted or transformed with no fear of data loss.</p><p>Configuration for JDP itself is stored in configuration files which are not associated with the cache.</p><p>If yet another tracker (test, bug tracker or something else) is required then it should be created as a separate service.</p><h2><a class="nav-anchor" id="Distributed-Data-Cache-1" href="#Distributed-Data-Cache-1">Distributed Data Cache</a></h2><p>The data sources are very slow and unreliable some of the time. So we periodically query the sources and cache the data into a Redis master node. Clients can then be configured to replicate from this master node.</p><p>Replicating from the master node is significantly faster than downloading all required data from the original sources.</p><p>Each client has (by default, but it is configurable) has its own local Redis instance. This replicates from the master node, but the client can write to it without effecting the master. In the future we could provide some mechanism for clients to send changes back to the master.</p><p>Redis could be replaced if necessary or we could insert our own replication layer. The data is stored using BSON.jl to serialise Julia structs, but it can be changed if necessary. The storage layer is fairly well decoupled from the rest of the application.</p><p>The reason we are using Redis is because it is simple and easy, yet supports replication. We are probably abusing its replication and this may not scale, so one should not assume that we will be using Redis forever.</p><h2><a class="nav-anchor" id="Mostly-in-memory-data-1" href="#Mostly-in-memory-data-1">Mostly in memory data</a></h2><p>The data is mostly brought into memory before being queried. Some filtering may be necessary before fetching from the data store, but most things are done in memory.</p><p>The reason for this is to maximise freedom. We make few assumptions about what algorithms or queries the user will want to make on the data. They may wish to use SQL like statements or they may not. They may want to put the data in a graph and run some graph algorithm on it.</p><p>The data is stored in the data cache in whatever way we see fit, then it can be fetched and transformed into two or more formats (currently plain structs or DataFrames).</p><p>Doing everything in memory places few restrictions on how the data is stored or how it is queried. It is not a performance optimisation except in some quite rare scenarios.</p><p>We may need to create indexes for very common queries. For example filtering test results by date or product group. However these must be queries used in almost every script that have a significant positive effect.</p><h2><a class="nav-anchor" id="Julia-1" href="#Julia-1">Julia</a></h2><p>Yes, we are using some crazy language you have never heard of. Some of the reasons are as follows.</p><h3><a class="nav-anchor" id="Positives-1" href="#Positives-1">Positives</a></h3><ol><li>It has a strong type system which can optionally be inferred. This is good for the core library where we want to type annotate everything for static analysis and self documentation. It is also good for quickly writing scripts/reports where the user doesn&#39;t care/know what type gets used. Although personally I like to annotate almost everything.</li><li>It behaves mostly like a scripting language, but is compiled to native code (LLVM). In theory it can be optimised for C like performance, but it has an advanced symbolic macro system and you can dynamically build types and objects like in a scripting language.</li><li>It is popular with people doing a lot data analysis, like scientists and such.</li><li>It has a nice system for displaying any object graphically in different backends (e.g. as html, vectors, markdown, plain text, ...).</li><li>I managed to get the basics working very quickly.</li><li>It is not completely alien compared to more popular languages. The learning curve is fairly low for making basic changes. It then increased rapidly once the type system is involved which I actually consider a good thing.</li><li>It interfaces well with C and Python<a href="#footnote-1">[1]</a></li><li>It makes me happy.</li></ol><div class="footnote" id="footnote-1"><a href="#footnote-1"><strong>[1]</strong></a><p>Untested by us, but it is probably mostly true. If it interfaces with C well it probably also works well with any other language which exports sane symbols.</p></div><h3><a class="nav-anchor" id="Negatives-1" href="#Negatives-1">Negatives</a></h3><p>On the downside:</p><ol><li>In practice it is not very quick because many libraries are not optimised.</li><li>It looks alien to C/Perl programmers.</li><li>Even common libraries are often immature and contain bugs</li><li>Python/R/Scalar/X exists and people will ask why aren&#39;t you using Python/R/Scalar/X.</li><li>The startup time is quite bad because it often decides to recompile stuff on the fly.</li><li>It&#39;s just generally not very mature and stuff breaks with major language releases.</li><li>There are no packages for individual libraries.</li><li>Has some weird syntax and behavior which I think will need to be changed at some point.</li></ol><p>Please note that I have repeatedly looked round at alternatives to Julia. Something really bad would have to happen at this point for us to change it. Also in the future if people wish to write scripts/reports in Python they should be able to. It is only the library which is limited to Julia and in fact parts could be written in C or <code>another-really-fast-language</code> if really necessary.</p><h2><a class="nav-anchor" id="Jupyter-(formally-known-as-IPython)-Notebooks-for-reports/scripts-1" href="#Jupyter-(formally-known-as-IPython)-Notebooks-for-reports/scripts-1">Jupyter (formally known as IPython) Notebooks for reports/scripts</a></h2><p>For some of the reports/scripts we use Jupyter which is a graphical REPL of sorts. It allows you to write blocks of code which produce some object which can be graphically represented below the code block (cell). It also allows blocks of Markdown to be rendered inline. The code blocks can all be run in sequence or individually.</p><p>To experienced C hackers it looks like baby&#39;s first coding IDE, but it is very useful for creating report prototypes because you can render HTML/Markdown/SVG inline and quickly rerun a particular bit of code (like a REPL).</p><p>Also JDP is not necessarily just aimed at developers as end users. Jupyter provides something resembling a GUI, but with all the wires hanging out. There is also the possibility of hosting the notebooks remotely for people who can&#39;t/won&#39;t install JDP locally.</p><p>Jupyter notebooks can be replaced or supplemented with something else if it better suites a given use case. Also scripts and reports do not need to be written as Jupyter notebooks; it is down to the author&#39;s discretion.</p><footer><hr/><a class="previous" href="../trackers/"><span class="direction">Previous</span><span class="title">Trackers</span></a></footer></article></body></html>
