{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Status Differences\n",
    "\n",
    "This script looks for differences between test results to find interesting changes. When it finds something which may be relevant it can notify any interested parties. This uses the [JDP framework](https://rpalethorpe.io.suse.de/jdp/).\n",
    "\n",
    "First we need to build up our data structures to create the test matrix. There are some stats here which may be useful, but otherwise you can safely skip this part most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitors library source files and recompiles them after most changes\n",
    "import Revise\n",
    "\n",
    "# Run the init script which will setup the JDP project if necessary\n",
    "include(\"../src/init.jl\")\n",
    "\n",
    "# Bring DataFrame's _members_ into our namespace, so we can call them directly\n",
    "using DataFrames\n",
    "import DataStructures: SortedDict, SortedSet, SDSemiToken\n",
    "import Dates: Day\n",
    "\n",
    "# import the markdown string literal/macro\n",
    "import Markdown: @md_str\n",
    "\n",
    "# Import some libraries from the JDP project\n",
    "using JDP.Conf\n",
    "using JDP.Trackers.OpenQA    # Contains functions for dealing with the OpenQA web API\n",
    "using JDP.Trackers.Bugzilla  # Functions for accessing the Bugzilla API(s)\n",
    "using JDP.Repository\n",
    "using JDP.Spammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allres = Repository.fetch(OpenQA.TestResult, Vector, \"osd\", OpenQA.RecentOrInterestingJobsDef)\n",
    "\n",
    "md\"We have **$(length(allres))** results in total\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only show results for a single product, which can be set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"sle-15-SP1-Installer-DVD\"\n",
    "cloudproduct = \"sle-15-SP1\"\n",
    "\n",
    "prodres = filter(allres) do res\n",
    "    res.product == product\n",
    "end\n",
    "\n",
    "cloudprodres = filter(allres) do res\n",
    "    startswith(res.product, cloudproduct) && (\"Public Cloud\" in res.flags)\n",
    "end\n",
    "\n",
    "md\"\"\"\n",
    "We have **$(length(prodres))** test results for $(product) and $(length(cloudprodres)) for $(cloudproduct) cloud\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builds = SortedDict(parse(Float64, res.build) => res.build for res in prodres)\n",
    "\n",
    "totalbuilds = length(builds)\n",
    "recentnum = max(0, min(9, totalbuilds - 9))\n",
    "recentbuilds = SortedDict(k => v for (k, v) in collect(pairs(builds))[end - recentnum + 1:end])\n",
    "rbs = join(map(b -> \"**$b**\", values(recentbuilds)), \", \", \" and \")\n",
    "\n",
    "md\"We have **$totalbuilds** builds in total. The last $recentnum are $rbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbuilds = SortedDict(parse(Float64, res.build) => res.build for res in cloudprodres)\n",
    "\n",
    "cloudtotalbuilds = length(cloudbuilds)\n",
    "cloudrecentnum = max(0, min(9, cloudtotalbuilds - 9))\n",
    "cloudrecentbuilds = SortedDict(k => v for (k, v) in collect(pairs(cloudbuilds))[end - cloudrecentnum + 1:end])\n",
    "cloudrbs = join(map(b -> \"**$b**\", values(cloudrecentbuilds)), \", \", \" and \")\n",
    "\n",
    "md\"We have **$totalbuilds** builds in total. The last $cloudrecentnum are $cloudrbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodtestnames = map(res -> (suit = res.suit, name = res.name, arch = res.arch, flags = res.flags), \n",
    "    prodres) |> unique |> SortedSet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudprodtestnames = map(res -> (suit = res.suit, name = res.name, arch = res.arch, flags = res.flags), \n",
    "    cloudprodres) |> unique |> SortedSet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_diff_matrix(testnames, recentbuilds, prodres; \n",
    "        bad_build_limit=0.25, bad_arch_limit=0.25, bad_test_limit=0.25, no_limits=false)\n",
    "    \n",
    "    if no_limits\n",
    "        bad_build_limit = bad_arch_limit = bad_test_limit = 1\n",
    "    end\n",
    "    # First build a dictionary with build names for keys and test dictionarys for values\n",
    "    buildsres = SortedDict(\n",
    "        build => Dict{NamedTuple, Any}(name => nothing for name in testnames) for build in keys(recentbuilds)\n",
    "    )\n",
    "\n",
    "    # Find the best result for each build-test pair\n",
    "    for res in Iterators.filter(res -> haskey(buildsres, parse(Float64, res.build)), prodres)\n",
    "        name = (suit = res.suit, name = res.name, arch = res.arch, flags = res.flags)\n",
    "        bres = buildsres[parse(Float64, res.build)]\n",
    "        if haskey(bres, name) && (bres[name] == nothing || bres[name].result != \"passed\")\n",
    "            bres[name] = res\n",
    "        end \n",
    "    end\n",
    "\n",
    "    bad_builds = Set{Float64}()\n",
    "    bad_builds_for_arch = Dict{String, Set{Float64}}()\n",
    "\n",
    "    # Remove builds where many of the tests were not run as this usually means there was\n",
    "    # an obvious problem with the testing infrastructure. Also remove all tests for a \n",
    "    # particular architecture in a build, if many tests on that arch returned no result.\n",
    "    for (build, tests) in buildsres\n",
    "        none_count = 0\n",
    "        arch_none_count = Dict{String, Int}()\n",
    "        arch_count = Dict{String, Int}()\n",
    "\n",
    "        for (id, res) in tests\n",
    "            if res == nothing || res.result == \"none\"\n",
    "                none_count += 1\n",
    "                arch_none_count[id.arch] = get(arch_none_count, id.arch, 0) + 1\n",
    "            end\n",
    "            arch_count[id.arch] = get(arch_count, id.arch, 0) + 1\n",
    "        end\n",
    "\n",
    "        if none_count / length(testnames) > bad_build_limit\n",
    "            push!(bad_builds, build)\n",
    "        else\n",
    "            for (arch, count) in arch_none_count\n",
    "                if count / arch_count[arch] > bad_arch_limit\n",
    "                    for (id, res) in buildsres[build]\n",
    "                        if id.arch == arch\n",
    "                            push!(get(Set, bad_builds_for_arch, arch), build)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    for build in bad_builds\n",
    "        delete!(buildsres, build)\n",
    "    end\n",
    "\n",
    "    failed_testnames = []\n",
    "    final_tests = []\n",
    "    for name in testnames\n",
    "        boring = true\n",
    "        none_count = 0\n",
    "\n",
    "        statuses = Dict{String, Int}()\n",
    "        for (build, results) in buildsres\n",
    "            if build in get(bad_builds_for_arch, name.arch, Set())\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            res = results[name]\n",
    "            if res == nothing\n",
    "                statuses[\"none\"] = get(statuses, \"none\", 0) + 1\n",
    "            else\n",
    "                statuses[res.result] = get(statuses, res.result, 0) + 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if length(keys(statuses)) > 1\n",
    "            boring = false\n",
    "        end\n",
    "\n",
    "        if get(statuses, \"none\", 0) / length(buildsres) > bad_test_limit\n",
    "            boring = true\n",
    "        end\n",
    "        \n",
    "        final = length(buildsres) > 0 ? buildsres[end][name] : nothing\n",
    "        if final ≠ nothing && final.result == \"passed\"\n",
    "            boring = true\n",
    "        end\n",
    "\n",
    "        if boring\n",
    "            for k in keys(buildsres)\n",
    "                delete!(buildsres[k], name)\n",
    "            end\n",
    "        else\n",
    "            push!(failed_testnames, name)\n",
    "            push!(final_tests, final)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Put the results into columns for display in a table\n",
    "    buildcols = [[let res = buildsres[build][name]\n",
    "        res == nothing ? \"none\" : res.result\n",
    "    end for name in failed_testnames] for build in keys(buildsres)]\n",
    "    headers = [Symbol(\"Suit\"), Symbol(\"Test\"), Symbol(\"Arch\"), Symbol.(keys(buildsres))...]\n",
    "\n",
    "    (failed = failed_testnames, builds = buildcols, headers = headers, final_tests = final_tests)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltp = build_diff_matrix(filter(tn -> tn.suit[1] == \"LTP\", collect(prodtestnames)), recentbuilds, prodres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstests = build_diff_matrix(filter(tn -> tn.suit[1] == \"fstests\", collect(prodtestnames)), recentbuilds, prodres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa =  build_diff_matrix(cloudprodtestnames, cloudrecentbuilds, cloudprodres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpcres = filter(collect(prodtestnames)) do tn\n",
    "    length(tn.suit) > 1 && tn.suit[1:2] == [\"OpenQA\", \"HPC\"]\n",
    "end\n",
    "hpc =  build_diff_matrix(hpcres, recentbuilds, prodres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherres = filter(collect(prodtestnames)) do tn\n",
    "    suit = tn.suit[1]\n",
    "    suit ≠ \"LTP\" && suit ≠ \"fstests\" && suit ≠ \"IPA\" && get(tn.suit, 2, nothing) ≠ \"HPC\"\n",
    "end\n",
    "others =  build_diff_matrix(otherres, recentbuilds, prodres);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below are the diff matrices for various test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_matrix(m) = withenv(\"LINES\" => 200) do\n",
    "    display(\n",
    "        DataFrame([\n",
    "                map(t -> join(t.suit, \":\"), m.failed), \n",
    "                map(t -> t.name * \" \" * join(t.flags, \" \"), m.failed),\n",
    "                map(t -> t.arch, m.failed), \n",
    "                m.builds...],\n",
    "            m.headers)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_matrix(ltp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(fstests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(ipa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(hpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notifications\n",
    "\n",
    "Next we notify interested persons of the changes in test results. To limit the amount of noise, each test can only be included in a notification to the specified set of users once a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maybe_notify(mat, users)\n",
    "    changed_tests = []\n",
    "    users_key = join(users, \"&\")\n",
    "\n",
    "    for (name, test) in zip(mat.failed, mat.final_tests)\n",
    "        test_id = join(name.suit, \":\") * \":$(name.name)@$(name.arch)[\" * join(name.flags, \",\")\n",
    "        flag_key = \"diff-notified-$test_id]$users_key\"\n",
    "        oldres = Repository.get_temp_flag(flag_key)\n",
    "        newres = test ≠ nothing ? test.result : \"none\"\n",
    "        @debug test_id repr(oldres) newres\n",
    "        if oldres ≠ newres\n",
    "            push!(changed_tests, (test_id, test))\n",
    "            Repository.set_temp_flag(flag_key, newres, Day(1))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if !isempty(changed_tests)\n",
    "        io = IOBuffer()\n",
    "        println(io, \"The following tests appear to have changed status recently:\\n\")\n",
    "\n",
    "        for (test_id, test) in changed_tests\n",
    "            if test ≠ nothing\n",
    "                show(io, MIME(\"text/markdown\"), test)\n",
    "                println(io)\n",
    "            else\n",
    "                println(io, test_id)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        print(io, \"\\nSee the [Status Difference Report](https://rpalethorpe.io.suse.de/jdp/reports/Report-Status-Diff.html) for details\")\n",
    "\n",
    "        Spammer.post_message(Spammer.Message(String(take!(io)), users))\n",
    "    end\n",
    "    \n",
    "    changed_tests\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = maybe_notify(ltp, [\"rpalethorpe\", \"metan\", \"pvorel\", \"sebchlad\", \"mmoese\"])\n",
    "md\"Sent **$(length(changes))** change notifications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = maybe_notify(fstests, [\"lansuse\", \"yosun\"])\n",
    "md\"Sent **$(length(changes))** change notifications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = maybe_notify(ipa, [\"cfconrad\", \"jlausuch\"])\n",
    "md\"Sent **$(length(changes))** change notifications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = maybe_notify(hpc, [\"sebchlad\"])\n",
    "md\"Sent **$(length(changes))** change notifications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = maybe_notify(others, [\"rpalethorpe\"])\n",
    "md\"Sent **$(length(changes))** change notifications\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
